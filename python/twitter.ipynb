{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (4.14.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from tweepy) (3.2.2)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from tweepy) (2.32.3)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from transformers) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2024.8.30)\n",
      "Requirement already satisfied: colorama in c:\\users\\deepak gudla\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy transformers python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching tweets from user: deepakgudla1357\n",
      "Resolved User ID: 1027909976357003264\n",
      "\n",
      "Fetched Tweets:\n",
      "- RT @SuccinctJT: 1/ Todayâ€™s zkVMs are likely riddled with bugs. We should stop pretending otherwise. My latest blog post outlines our roadmaâ€¦\n",
      "- RT @danbrettig: Here we go #AUSvIND https://t.co/SXhZSOcutU\n",
      "- RT @rogerfederer: Vamos, @RafaelNadal!\n",
      "Â \n",
      "As you get ready to graduate from tennis, Iâ€™ve got a few things to share before I maybe get emotioâ€¦\n",
      "- RT @tkstanczak: In the recently published 6-part Ethereum roadmap discussion, @VitalikButerin highlighted that \"our task is to bring the roâ€¦\n",
      "- RT @gd3kr: introducing BLENDERGPT - the fastest way to generate 3D assets and import them seamlessly into Blender.\n",
      "\n",
      "text to 3D in ~20 seconâ€¦\n",
      "- RT @BanklessHQ: Vitalik dropped 6 detailed articles about the Ethereum roadmap\n",
      "\n",
      "Here's our condensed ELI5 cheat sheet ðŸ‘‡â€¦ https://t.co/DEJp1â€¦\n",
      "- RT @dlubarov: Quick update: it's now over 2 million hashes per second ðŸ’ª\n",
      "\n",
      "Recent speedups were mostly memory-related: avoiding copies, skippâ€¦\n",
      "- RT @evan_van_ness: ETHEREUM ROADMAP EXPLAINER FOR THE REST OF US, part 1 \n",
      "\n",
      "This thread will attempt to dumb down @VitalikButerin's series sâ€¦\n",
      "- RT @ks_kulk: As @VitalikButerin points out, there are three Egyptian god cards that are about to be played in cryptography over the next seâ€¦\n",
      "- RT @zeroknowledgefm: zkSummit wrapped up on Tuesday - all videos will be dropping over the next few weeks on youtube! In the meantime, catcâ€¦\n",
      "\n",
      "Generating summary...\n",
      "\n",
      "Summary:\n",
      ": 1/ Todayâ€™s zkVMs are likely riddled with bugs. We should stop pretending otherwise. RT @dlubarov: Quick update: it's now over 2 million hashes per\n",
      "\n",
      "Posting summary to Twitter timeline...\n",
      "Summary posted successfully: 1861813040007750116\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Step 1: Fetch the latest 10 tweets from a user\n",
    "def fetch_latest_tweets(username, client, max_results=10):\n",
    "    try:\n",
    "        # Resolve the username to user ID\n",
    "        response = client.get_user(username=username)\n",
    "        if response.data:\n",
    "            user_id = response.data.id\n",
    "            print(f\"Resolved User ID: {user_id}\")\n",
    "        else:\n",
    "            raise Exception(\"Failed to resolve username. User not found.\")\n",
    "\n",
    "        # Fetch the latest tweets\n",
    "        tweets = client.get_users_tweets(\n",
    "            id=user_id,\n",
    "            max_results=max_results,\n",
    "            tweet_fields=[\"created_at\", \"text\"],\n",
    "        )\n",
    "        if tweets.data:\n",
    "            return [tweet.text for tweet in tweets.data]\n",
    "        else:\n",
    "            print(\"No tweets found for this user.\")\n",
    "            return []\n",
    "    except tweepy.TweepyException as e:\n",
    "        print(f\"Tweepy Error: {e}\")\n",
    "        return []\n",
    "    except Exception as ex:\n",
    "        print(f\"Error: {ex}\")\n",
    "        return []\n",
    "\n",
    "# Step 2: Summarize tweets using a pre-trained model\n",
    "def summarize_tweets(tweets, model_name=\"t5-small\"):\n",
    "    try:\n",
    "        # Load the summarization model\n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "\n",
    "        # Combine tweets into a single text input\n",
    "        input_text = \"Summarize the following tweets into a single post:\\n\" + \"\\n\".join(tweets)\n",
    "\n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "        # Generate the summary\n",
    "        summary_ids = model.generate(\n",
    "            inputs.input_ids,\n",
    "            max_length=50,           # Maximum length of the summary\n",
    "            num_beams=5,             # Beam search for better quality\n",
    "            early_stopping=True      # Stop early when the result is stable\n",
    "        )\n",
    "\n",
    "        # Decode and return the summary\n",
    "        summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "        return summary\n",
    "    except Exception as ex:\n",
    "        print(f\"Error in summarization: {ex}\")\n",
    "        return \"Error: Unable to generate summary.\"\n",
    "\n",
    "# Step 3: Post the summary to your Twitter timeline\n",
    "def post_summary_to_timeline(summary, client):\n",
    "    try:\n",
    "        response = client.create_tweet(text=summary)\n",
    "        print(f\"Summary posted successfully: {response.data['id']}\")\n",
    "    except tweepy.TweepyException as e:\n",
    "        print(f\"Error while posting summary: {e}\")\n",
    "\n",
    "# Step 4: Main function to integrate fetching, summarizing, and posting\n",
    "def main():\n",
    "    # Load Twitter API credentials from .env\n",
    "    bearer_token = os.getenv(\"TWITTER_BEARER_TOKEN\")\n",
    "    consumer_key = os.getenv(\"TWITTER_CONSUMER_KEY\")\n",
    "    consumer_secret = os.getenv(\"TWITTER_CONSUMER_SECRET\")\n",
    "    access_token = os.getenv(\"TWITTER_ACCESS_TOKEN\")\n",
    "    access_token_secret = os.getenv(\"TWITTER_ACCESS_TOKEN_SECRET\")\n",
    "\n",
    "    if not all([bearer_token, consumer_key, consumer_secret, access_token, access_token_secret]):\n",
    "        print(\"Error: Missing Twitter API credentials in .env file.\")\n",
    "        return\n",
    "\n",
    "    client = tweepy.Client(\n",
    "        bearer_token=bearer_token,\n",
    "        consumer_key=consumer_key,\n",
    "        consumer_secret=consumer_secret,\n",
    "        access_token=access_token,\n",
    "        access_token_secret=access_token_secret\n",
    "    )\n",
    "\n",
    "    # Username to fetch tweets from\n",
    "    username = os.getenv(\"TWITTER_USERNAME\")  # Replace with the desired username\n",
    "\n",
    "    print(f\"Fetching tweets from user: {username}\")\n",
    "    tweets = fetch_latest_tweets(username, client)\n",
    "\n",
    "    if tweets:\n",
    "        print(\"\\nFetched Tweets:\")\n",
    "        for tweet in tweets:\n",
    "            print(f\"- {tweet}\")\n",
    "\n",
    "        print(\"\\nGenerating summary...\")\n",
    "        summary = summarize_tweets(tweets)\n",
    "        print(\"\\nSummary:\")\n",
    "        print(summary)\n",
    "\n",
    "        print(\"\\nPosting summary to Twitter timeline...\")\n",
    "        post_summary_to_timeline(summary, client)\n",
    "    else:\n",
    "        print(\"No tweets available for summarization.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
